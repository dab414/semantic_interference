---
title: "Inferential Analyses"
output:
  html_document:
    df_print: paged
---

## Inferential Analyses for Sematic Interference (Experiment 1)
The purpose of this notebook is to extend the ANOVA analysis into a generalized linear mixed model analysis, where random effects grouped by participants and items are controlled for. I'm going to use this notebook for model selection and, once I've found the best-fitting model, I'll use a separate notebook to assess its predictive validity using the kfolds crossvalidation technique.

```{r}
library(tidyverse)
library(data.table)
library(lme4)
library(car)
```

```{r}
current_data <- fread('../data/exp1_clean.csv', stringsAsFactors = TRUE)
head(current_data)
str(current_data)
```

```{r}
# current_data <- current_data %>% 
#   mutate(#block = factor(recode(block, `1` = 'one', `2` = 'two')),
#          subject = as.factor(subject),
#          cycle = factor(recode(cycle, 
#                         `1` = 'one',
#                         `2` = 'two',
#                         `3` = 'three',
#                         `4` = 'four',
#                         `5` = 'five')))
#   

## could not get this code to work in dplyr::recode() for the life of me
current_data$block <- as.factor(current_data$block)
levels(current_data$block) <- c('one','two')
current_data$subject <- as.factor(current_data$subject)
current_data$cycle <- as.factor(current_data$cycle)
levels(current_data$cycle) <- c('one','two', 'three','four','five')

contrasts(current_data$block)  <- c(-.5,.5)
contrasts(current_data$context)  <- c(-.5,.5)
contrasts(current_data$item_type)  <- c(-.5,.5)
summary(current_data)

```
```{r}
current_data$block <- as.factor(current_data$block)
levels(current_data$block) <- c('one','two')
summary(current_data$block)
```


Let this run for a good ~45 min, and nothing... the wheels kept spinning

Running a version with only main effects and intercepts (no covariances)

```{r eval = FALSE}
start <- Sys.time()
m1 <- lmer(rt ~ cycle * item_type * context * block + 
             (1 | subject) + 
             (0 + cycle | subject) + 
             #(0 + item_type | subject) + 
             #(0 + context | subject) + 
             (0 + block | subject) + 
             (1 | item) + 
             #(0 + cycle | item) + 
             (0 + item_type | item) + 
             (0 + context | item),# + 
             #(0 + block | item),
           ## intentionally jacking up the maxfun parameter here; it's been running for ~ 20 min and still going
           data = current_data)#, control = lmerControl(optimizer = 'bobyqa', optCtrl = list(maxfun = 100000)))
Sys.time() - start
```

6/5
Okay so the difference between the model below and the one above is below i'm only dealing with intercepts, not slopes. For example, `(1 | subject:cycle)` is measuring the intercept for cycle for *each* subject. 

```{r eval=FALSE}
start <- Sys.time()
## this converges in ~ 1 min
m2 <- lmer(rt ~ cycle * item_type * context * block + 
             (1 | subject) + 
             (1 | subject:cycle) + 
             (1 | subject:item_type) + 
             (1 | subject:context) + 
             (1 | subject:block) + 
             (1 | item) + 
             (1 | item:cycle) + 
             (1 | item:item_type) + 
             (1 | item:context) +
             (1 | item:block),
           data = current_data, control = lmerControl(optimizer = 'Nelder_Mead', optCtrl = list(maxfun = 100000)))
Sys.time() - start
```
Scaling the model down to reach convergence and testing the significance of the random parameters via LRTs.

```{r}
m4 <- lmer(rt ~ cycle * item_type * context * block + 
             (1 | subject) + 
             (1 | subject:cycle) + 
             (1 | subject:item_type) + 
             #(1 | subject:context) + 
             (1 | subject:block) + 
             #(1 | item) + 
             #(1 | item:cycle) + 
             (1 | item:item_type) + 
             (1 | item:context),# +
             #(1 | item:block),
           data = current_data, control = lmerControl(optimizer = 'Nelder_Mead', optCtrl = list(maxfun = 100000)))
```

```{r}
start <- Sys.time()
m5 <- lmer(rt ~ cycle * item_type * context * block + 
             (1 | subject) + 
             (1 | subject:cycle) + 
             #(1 | subject:item_type) + 
             #(1 | subject:context) + 
             (1 | subject:block) + 
             #(1 | item) + 
             #(1 | item:cycle) + 
             (1 | item:item_type) + 
             (1 | item:context),# +
             #(1 | item:block),
           data = current_data, control = lmerControl(optimizer = 'Nelder_Mead', optCtrl = list(maxfun = 100000)))
Sys.time() - start
```

```{r}
anova(m4,m5)
```


Subject by item type is right on the fringe of being significant, but the pattern of effects doesn't change across those models, so I'm inclined to keep the simpler one. So now I think I have a good model and it converges in about five seconds.

```{r}
Anova(m5)
```












